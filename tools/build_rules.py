#!/usr/bin/env python3

import re
import os
import hashlib
import json
from glob import glob

CURDIR = os.path.dirname(os.path.realpath(__file__))
BUILDDIR = os.path.join(CURDIR, '..', 'build')
RULESDIR = os.path.join(CURDIR, '..', 'rules')
SOURCES_TXT = ('backend.txt', 'frontend.txt', ) # 'burner-domains.txt'
SOURCES_YAR = ('custom.yar',)
RULENAME = 'all-confirmed'
WHITELISTDIR = os.path.join(CURDIR, '..', 'corpus', 'whitelisted')

yara_match_pattern = '\$ = (?:/(.+)/|"(.+)")\s*\n'


"""
Todo: clean up mess with multiple escape strategies
to facilitate py2/3.
"""


def sigs_to_grep_patterns(fh):
    p = set()
    for line in fh:
        line = line.strip()
        if not line or line.startswith('#'):
            continue

        if line.startswith('/'):
            p.add(line[1:-1])
        else:
            p.add(re.escape(line).replace(r'\'', "'"))
    return p


def find_file_hashes(root):
    allhashes = dict()
    for prefix, dirs, files in os.walk(root):
        for fn in files:
            fullpath = os.path.join(prefix, fn)

            # /malware/whitelisted/NeoPI/animal_shell_poc.php => NeoPI/animal_shell_poc.php
            relpath = fullpath[len(root) + 1:]

            with open(fullpath, 'rb') as fh:
                hash = hashlib.sha1(fh.read()).hexdigest()
                allhashes[hash] = relpath
    return allhashes


def sig_to_name(sig):
    # produce somewhat readable name from a signature

    # 
    try:  # py2
        h = hashlib.sha1(sig).hexdigest()[:8]
    except TypeError:  # py3
        h = hashlib.sha1(bytes(sig, 'utf-8')).hexdigest()[:8]
    ascii = re.sub(r'[^\w\d]+','_', sig).strip('_')

    if ascii:
        return 'r_' + ascii[:16].rstrip('_') + '_' + h
    else:
        return 'r_' + h

def escape_string(s):
    # py2/3 compatible
    try:
        new = s.encode('string_escape').replace(r"\'","'")
    except LookupError:
        new = s.encode('unicode_escape').decode('utf-8').replace(r"\'","'")
    return new 


def sigs_to_yara(fh):
    # convert literals or regex to yara rule

    yarasigs = ""

    for line in fh:
        line = line.strip()
        if not line or line.startswith('#'):
            continue

        name = sig_to_name(line)

        if line.startswith('/'):
            pass
        else:  # literal
            # re.escape escapes too much, encode() escapes too little (no ")
            line = '"' + re.sub(r'([\\"])', r'\\\1', line) + '"'

        yarasigs += "rule {} {{\n\tstrings: $ = {}\n\tcondition: any of them\n}}\n".format(name, line).lstrip()

    return yarasigs


def write_grep_rules():

    patterns = set()

    for path in SOURCES_TXT:
        with open(os.path.join(RULESDIR, path)) as fh:
            patterns = patterns.union(sigs_to_grep_patterns(fh))

    with open(os.path.join(BUILDDIR, RULENAME + '.txt'), 'w') as fh:
        for p in sorted(patterns):
            fh.write(p + '\n')


def write_yara_rules():
    with open(os.path.join(BUILDDIR, RULENAME + '.yar'), 'w') as fhout:
        fhout.write("/* AUTO GENERATED BY <{0}> DO NOT EDIT\n\nWHITELIST = {1}\n\n*/\n\n".format(
            __file__,
            json.dumps(find_file_hashes(WHITELISTDIR), indent=2, sort_keys=True)
        ))

        for path in SOURCES_TXT:
            with open(os.path.join(RULESDIR, path)) as fhin:
                fhout.write(sigs_to_yara(fhin))
                fhout.write('\n')
        
        for path in SOURCES_YAR:  ## custom rules that can't be grepped
            with open(os.path.join(RULESDIR, path)) as fhin:
                fhout.write(fhin.read())


def write_all_rules():
    write_grep_rules()
    write_yara_rules()
    print("Written build files to {}".format(BUILDDIR))


if __name__ == '__main__':
    write_all_rules()
